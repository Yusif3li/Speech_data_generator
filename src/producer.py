import os
import time
import random
import re
import sys
import struct
from google import genai
from google.genai import types
from dotenv import load_dotenv

# --- SETUP ---
load_dotenv()
api_key = os.getenv("GENAI_API_KEY")
if not api_key:
    print("âŒ ERROR: API Key missing in .env")
    sys.exit(1)

client = genai.Client(api_key=api_key)
STAGING_DIR = "staging"
os.makedirs(STAGING_DIR, exist_ok=True)

# --- CONFIGURATION ---
# Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ÙƒØªØ§Ø¨Ø©
TEXT_MODEL_ID = "gemini-2.5-flash"

# Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ØµÙˆØª (ØªÙ… ØªØµØ­ÙŠØ­ Ø§Ù„Ø§Ø³Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¨ØªØ§Ø¹ØªÙƒ)
# Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ¯Ø¹Ù… Native Multi-Speaker
AUDIO_MODEL_ID = "gemini-2.5-flash-preview-tts"

# TOPICS
CS_TOPICS = [
    "Binary Search Trees", "TCP vs UDP", "Restful APIs", "Docker Containers",
    "Neural Networks Backpropagation", "SQL Joins", "Big O Notation",
    "Operating System Deadlocks", "Hashing Algorithms", "Git Branching"
]

def clean_filename(text):
    return re.sub(r'[\\/*?:"<>|]', "", text).replace(" ", "_")

def convert_to_wav(audio_data: bytes, mime_type: str) -> bytes:
    """Adds WAV header to Raw PCM data"""
    bits_per_sample = 16
    rate = 24000
    try:
        parts = mime_type.split(";")
        for param in parts:
            if "rate=" in param:
                rate = int(param.split("=")[1])
    except:
        pass

    num_channels = 1
    data_size = len(audio_data)
    chunk_size = 36 + data_size
    byte_rate = rate * num_channels * (bits_per_sample // 8)
    block_align = num_channels * (bits_per_sample // 8)

    header = struct.pack(
        "<4sI4s4sIHHIIHH4sI",
        b"RIFF", chunk_size, b"WAVE", b"fmt ", 16, 1, num_channels,
        rate, byte_rate, block_align, bits_per_sample, b"data", data_size
    )
    return header + audio_data

def generate_random_episode(episode_number):
    topic = random.choice(CS_TOPICS)
    clean_topic = clean_filename(topic)
    episode_id = f"Ep{episode_number:03d}_{clean_topic}"
    
    print(f"\nğŸ¬ [Test Episode] Topic: {topic}")

    # --- STEP 1: GENERATE SCRIPT (FORCED ARABIC) ---
    print(f"   ğŸ“ Generating Script (using {TEXT_MODEL_ID})...")
    
    # ØªÙ… ØªØºÙŠÙŠØ± Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ø¶Ù…Ø§Ù† Ø®Ø±ÙˆØ¬ Ù†Øµ Ù…ØµØ±ÙŠ
    script_prompt = f"""
    Ø£Ù†Øª ÙƒØ§ØªØ¨ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ "Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ØªÙ‚Ù†ÙŠ" Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ©.
    Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: "{topic}"

    Ø§Ù„Ø´Ø®ØµÙŠØ§Øª:
    1. Speaker 1 (Ø³Ø§Ø±Ø©): Ø§Ù„Ù…Ø°ÙŠØ¹ØŒ ØªØªØ­Ø¯Ø« Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ø¨Ø³ÙŠØ·Ø©.
    2. Speaker 2 (Ø£Ø­Ù…Ø¯): Ø§Ù„Ø¶ÙŠÙ (Ù…Ù‡Ù†Ø¯Ø³ Ø¨Ø±Ù…Ø¬ÙŠØ§Øª)ØŒ ÙŠØªØ­Ø¯Ø« Ø¨Ù„Ù‡Ø¬Ø© Ù…ØµØ±ÙŠØ© Ù…Ø«Ù‚ÙØ© ÙˆÙŠØ³ØªØ®Ø¯Ù… Ù…ØµØ·Ù„Ø­Ø§Øª ØªÙ‚Ù†ÙŠØ© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.

    Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
    - Ø§ÙƒØªØ¨ Ø­ÙˆØ§Ø±Ø§Ù‹ Ù…Ø¯ØªÙ‡ Ø®Ù…Ø³ Ø¯Ù‚Ø§Ø¦Ù‚.
    - **Ø§ÙƒØªØ¨ Ø§Ù„Ø­ÙˆØ§Ø± Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø­Ø±ÙˆÙ Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù„ÙƒÙ†Ø© Ù…ØµØ±ÙŠØ© Ø¹Ø§Ù…ÙŠØ© (Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù„ÙƒÙ†Ø© Ù…ØµØ±ÙŠ).**
    - Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (Ù…Ø«Ù„ Algorithm, API) ÙˆÙ„ÙƒÙ† ÙÙŠ Ø³ÙŠØ§Ù‚ Ø¬Ù…Ù„ Ø¹Ø±Ø¨ÙŠØ©.
    - Ø§Ù„ØªØ²Ù… ØªÙ…Ø§Ù…Ø§Ù‹ Ø¨Ù‡Ø°Ø§ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª):
    Speaker 1: [Ø§Ù„ÙƒÙ„Ø§Ù… Ù‡Ù†Ø§]
    Speaker 2: [Ø§Ù„ÙƒÙ„Ø§Ù… Ù‡Ù†Ø§]
    """
    
    try:
        response = client.models.generate_content(
            model=TEXT_MODEL_ID,
            contents=script_prompt
        )
        script_text = response.text
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ù‚Ø¨Ù„ Ø§Ù„Ø­ÙØ¸
        if "Speaker 1:" not in script_text:
            print("   âš ï¸ Warning: Script format might be wrong, creating backup...")
        
        with open(f"{STAGING_DIR}/{episode_id}_script.txt", "w", encoding="utf-8") as f:
            f.write(script_text)
        print("   âœ… Script Saved (Arabic).")

    except Exception as e:
        print(f"   âŒ Script Error: {e}")
        return

    time.sleep(2)

    # --- STEP 2: GENERATE AUDIO (NATIVE MULTI-SPEAKER) ---
    print(f"   ğŸ”Š Generating Audio (using {AUDIO_MODEL_ID})...")
    
    try:
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ø£ØµÙ„ÙŠ (Native Config)
        generate_content_config = types.GenerateContentConfig(
            response_modalities=["AUDIO"],
            speech_config=types.SpeechConfig(
                multi_speaker_voice_config=types.MultiSpeakerVoiceConfig(
                    speaker_voice_configs=[
                        types.SpeakerVoiceConfig(
                            speaker="Speaker 1",
                            voice_config=types.VoiceConfig(
                                prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                    voice_name="Kore"
                                )
                            ),
                        ),
                        types.SpeakerVoiceConfig(
                            speaker="Speaker 2",
                            voice_config=types.VoiceConfig(
                                prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                    voice_name="Charon"
                                )
                            ),
                        ),
                    ]
                ),
            ),
        )

        contents = [
            types.Content(
                role="user",
                parts=[
                    types.Part.from_text(text=script_text),
                ],
            ),
        ]

        full_audio_data = bytearray()
        first_chunk_mime = "audio/wav"

        # Stream Generation
        for chunk in client.models.generate_content_stream(
            model=AUDIO_MODEL_ID,
            contents=contents,
            config=generate_content_config,
        ):
            if chunk.candidates and chunk.candidates[0].content.parts:
                part = chunk.candidates[0].content.parts[0]
                if part.inline_data:
                    full_audio_data.extend(part.inline_data.data)
                    first_chunk_mime = part.inline_data.mime_type
                    print(".", end="", flush=True)

        print("\n   ğŸ’¾ Saving merged audio...")
        
        final_wav = convert_to_wav(full_audio_data, first_chunk_mime)
        
        with open(f"{STAGING_DIR}/{episode_id}_full.wav", "wb") as f:
            f.write(final_wav)
            
        print(f"   âœ… Audio Saved: {episode_id}_full.wav")
        print("   ğŸ‰ Pipeline Success!")

    except Exception as e:
        print(f"\n   âŒ Audio Failed: {e}")

if __name__ == "__main__":
    print(f"ğŸš€ Generator Started. Target Model: {AUDIO_MODEL_ID}")
    generate_random_episode(1)